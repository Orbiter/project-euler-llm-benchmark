{
    "athene-v2:72b-q8_0": {
        "_context_size": 128,
        "_parameter_size": 72.7,
        "_quantization_level": 8,
        "python-100": 12.7
    },
    "qwen2.5:72b-instruct-q8_0": {
        "_context_size": 128,
        "_parameter_size": 72.7,
        "_quantization_level": 8,
        "python-100": 11.01
    },
    "qwen2.5-coder:14b-instruct-q8_0": {
        "_context_size": 128,
        "_parameter_size": 14.8,
        "_quantization_level": 8,
        "python-100": 9.7
    },
    "yi-coder:9b-chat-q8_0": {
        "_context_size": 128,
        "_parameter_size": 8.8,
        "_quantization_level": 8,
        "python-100": 8.57
    },
    "vanilj/Phi-4:Q8_0": {
        "_context_size": 16,
        "_parameter_size": 14.7,
        "_quantization_level": 8,
        "python-100": 7.81
    },
    "qwen2.5:7b-instruct-q8_0": {
        "_context_size": 128,
        "_parameter_size": 7.6,
        "_quantization_level": 8,
        "python-100": 6.4
    },
    "qwen2.5-coder:7b-instruct-q8_0": {
        "_context_size": 128,
        "_parameter_size": 7.6,
        "_quantization_level": 8,
        "python-100": 6.13
    },
    "nemotron:70b-instruct-q8_0": {
        "_context_size": 128,
        "_parameter_size": 70.6,
        "_quantization_level": 8,
        "python-100": 6.01
    },
    "qwen2-math:72b-instruct-q8_0": {
        "_context_size": 4,
        "_parameter_size": 72.7,
        "_quantization_level": 8,
        "python-100": 5.64
    },
    "gemma2:27b-instruct-q8_0": {
        "_parameter_size": 27.2,
        "_quantization_level": 8,
        "python-100": 5.18
    },
    "qwen2.5-coder:3b-instruct-q8_0": {
        "_context_size": 32,
        "_parameter_size": 3.1,
        "_quantization_level": 8,
        "python-100": 4.32
    },
    "tulu3:8b-q8_0": {
        "_parameter_size": 8.0,
        "_quantization_level": 8,
        "python-100": 3.64
    },
    "exaone3.5:7.8b-instruct-q8_0": {
        "_context_size": 32,
        "_parameter_size": 7.8,
        "_quantization_level": 8,
        "python-100": 3.55
    },
    "llama3.1:8b-instruct-q8_0": {
        "_context_size": 128,
        "_parameter_size": 8.0,
        "_quantization_level": 8,
        "python-100": 3.32
    },
    "exaone3.5:32b-instruct-q8_0": {
        "_context_size": 32,
        "_parameter_size": 32.0,
        "_quantization_level": 8,
        "python-100": 2.96
    },
    "qwen2.5:3b-instruct-q8_0": {
        "_context_size": 128,
        "_parameter_size": 3.1,
        "_quantization_level": 8,
        "python-100": 2.87
    },
    "granite3.1-dense:8b-instruct-q8_0": {
        "_context_size": 128,
        "_parameter_size": 8.2,
        "_quantization_level": 8,
        "python-100": 2.8
    },
    "exaone3.5:2.4b-instruct-q8_0": {
        "_context_size": 32,
        "_parameter_size": 2.7,
        "_quantization_level": 8,
        "python-100": 2.53
    },
    "qwen2-math:7b-instruct-q8_0": {
        "_context_size": 4,
        "_parameter_size": 7.6,
        "_quantization_level": 8,
        "python-100": 2.49
    },
    "gemma2:9b-instruct-q8_0": {
        "_context_size": 8,
        "_parameter_size": 9.2,
        "_quantization_level": 8,
        "python-100": 2.46
    },
    "yi-coder:1.5b-chat-q8_0": {
        "_context_size": 128,
        "_parameter_size": 1.5,
        "_quantization_level": 8,
        "python-100": 2.3
    },
    "llama3.2:latest": {
        "_context_size": 128,
        "_parameter_size": 3.21,
        "_quantization_level": 4,
        "python-100": 2.14
    },
    "qwen2.5:1.5b-instruct-q8_0": {
        "_context_size": 128,
        "_parameter_size": 1.5,
        "_quantization_level": 8,
        "python-100": 1.98
    },
    "qwen2.5-coder:1.5b-instruct-q8_0": {
        "_context_size": 32,
        "_parameter_size": 1.5,
        "_quantization_level": 8,
        "python-100": 1.95
    },
    "codegemma:7b-instruct-q8_0": {
        "_context_size": 8,
        "_parameter_size": 9.0,
        "_quantization_level": 8,
        "python-100": 1.81
    },
    "granite3.1-dense:2b-instruct-q8_0": {
        "_context_size": 128,
        "_parameter_size": 2.5,
        "_quantization_level": 8,
        "python-100": 1.07
    },
    "qwen2.5:0.5b-instruct-q8_0": {
        "_context_size": 128,
        "_parameter_size": 0.5,
        "_quantization_level": 8,
        "python-100": 1.01
    },
    "granite3.1-moe:3b-instruct-q8_0": {
        "_context_size": 128,
        "_parameter_size": 3.3,
        "_quantization_level": 8,
        "python-100": 0.78
    },
    "qwen2-math:1.5b-instruct-q8_0": {
        "_context_size": 4,
        "_parameter_size": 1.5,
        "_quantization_level": 8,
        "python-100": 0.61
    },
    "gemma2:2b-instruct-q8_0": {
        "_context_size": 8,
        "_parameter_size": 2.6,
        "_quantization_level": 8,
        "python-100": 0.39
    },
    "granite3.1-moe:1b-instruct-q8_0": {
        "_context_size": 128,
        "_parameter_size": 1.3,
        "_quantization_level": 8,
        "python-100": 0.24
    },
    "qwen2.5-coder:0.5b-instruct-q8_0": {
        "_context_size": 32,
        "_parameter_size": 0.5,
        "_quantization_level": 8,
        "python-100": 0.13
    },
    "tulu3:70b-q8_0": {
        "_parameter_size": 70.6,
        "_quantization_level": 8
    },
    "llama3.1:70b-instruct-q8_0": {
        "_parameter_size": 70.6,
        "_quantization_level": 8
    },
    "deepseek-coder-v2:236b-instruct-q2_K": {
        "_parameter_size": 235.7,
        "_quantization_level": 2
    },
    "llama3.2:1b-instruct-q8_0": {
        "_parameter_size": 1.2,
        "_quantization_level": 8
    },
    "deepseek-coder-v2:16b-lite-instruct-q8_0": {
        "_parameter_size": 15.7,
        "_quantization_level": 8
    },
    "opencoder:1.5b-instruct-q8_0": {
        "_parameter_size": 1.9,
        "_quantization_level": 8
    },
    "opencoder:8b-instruct-q8_0": {
        "_parameter_size": 7.8,
        "_quantization_level": 8
    },
    "falcon3:1b-instruct-q8_0": {
        "_parameter_size": 1.7,
        "_quantization_level": 8
    },
    "falcon3:3b-instruct-q8_0": {
        "_parameter_size": 3.2,
        "_quantization_level": 8
    },
    "falcon3:7b-instruct-q8_0": {
        "_parameter_size": 7.5,
        "_quantization_level": 8
    },
    "falcon3:10b-instruct-q8_0": {
        "_parameter_size": 10.3,
        "_quantization_level": 8
    },
    "llama3.3:70b-instruct-q8_0": {
        "_parameter_size": 70.6,
        "_quantization_level": 8
    },
    "Bio-Medical-Llama-3-8B-GGUF:Q8_0": {
        "_parameter_size": 8.0,
        "_quantization_level": 8
    },
    "nemotron:70b": {
        "_parameter_size": 70.6,
        "_quantization_level": 4
    },
    "qwen2.5-coder:32b-instruct-q8_0": {
        "_parameter_size": 32.8,
        "_quantization_level": 8
    },
    "qwq:32b-preview-q8_0": {
        "_parameter_size": 32.8,
        "_quantization_level": 8
    },
    "phi3:14b-medium-128k-instruct-q8_0": {
        "_parameter_size": 14.0,
        "_quantization_level": 8
    }
}